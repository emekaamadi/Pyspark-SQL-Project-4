{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a74a2f6f90017bcef716d63d8dc2e470",
     "grade": false,
     "grade_id": "cell-3c17da45e7b7645f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SIADS 516: Homework 4\n",
    "\n",
    "- **Dr. Chris Teplovs**, School of Information, University of Michigan\n",
    "- **Kris Steinhoff**, School of Information, University of Michigan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1c62f6c256ca075d290009bc3f4883c",
     "grade": false,
     "grade_id": "cell-02367b8cfece2a65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The AutograderHelper class provides methods used by the autograder.\n",
    "from autograder_helper import AutograderHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0477ef5614295bf8caf6e1096266bfa3",
     "grade": true,
     "grade_id": "inject_private_helper",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 0 points.\n",
    "# This cell has hidden code used to configure the autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd552a41671f29be3f94d538b25e5520",
     "grade": false,
     "grade_id": "cell-34b72f966bd3b156",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This homework assignment uses the Yelp Academic dataset, with which you should now be familiar.\n",
    "We have created a few cells to get you started, but you're largely on your own to devise solutions to the\n",
    "\"real-world\" questions below.\n",
    "\n",
    "In this assignment, provide solutions that use spark.sql() calls to query the dataset. For example, to find the answer to \"How many users have more than 100 \"cool\" votes?\", this:\n",
    "```\n",
    "query = \"\"\"\n",
    "SELECT count(*) FROM user WHERE cool > 100\n",
    "\"\"\"\n",
    "spark.sql(query).show()\n",
    "```\n",
    "is similar to:\n",
    "```\n",
    "user.filter('cool > 100').show()\n",
    "```\n",
    "But in this assignment, use the first approach. The autograder will check for the use of `spark.sql()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c34ef5c67d3c510a686b5e18d499db08",
     "grade": false,
     "grade_id": "cell-e1638183f41aa602",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Our usual Spark mantra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cea91b07d9a4bee525e3ed6d23d2d37",
     "grade": false,
     "grade_id": "cell-98c1a867a2e9c83b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/17 22:09:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('My First Spark application') \\\n",
    "    .getOrCreate() \n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba476caea9d89d002deede468dff6f08",
     "grade": false,
     "grade_id": "cell-c9ad81a944f5fd79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Load the JSON files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f46ca5ab7e2f08c41b5b4014d63c248e",
     "grade": false,
     "grade_id": "cell-a04e6cbc86f81133",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/17 22:10:01 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_business.json.gz')\n",
    "checkin = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_checkin.json.gz')\n",
    "review = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_review.json.gz')\n",
    "tip = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_tip.json.gz')\n",
    "user = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_user.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5cbdf5d60302f8ad654c74be9880857",
     "grade": false,
     "grade_id": "cell-811b05fe37080393",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Create temp views for the DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d1689383e4a34655a2f6790f22691d2",
     "grade": false,
     "grade_id": "cell-29e2438127b26344",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "business.createOrReplaceTempView(\"business\")\n",
    "checkin.createOrReplaceTempView(\"checkin\")\n",
    "tip.createOrReplaceTempView(\"tip\")\n",
    "review.createOrReplaceTempView(\"review\")\n",
    "user.createOrReplaceTempView(\"user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c883cedcf0fb749a8a224c2a0b882241",
     "grade": false,
     "grade_id": "cell-41d7ac10cefde0c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## -- EXAMPLE PROBLEM --\n",
    "\n",
    "Get a list of users named \"Kahlil\" with the number of their reviews tagged \"funny\".\n",
    "\n",
    "- The result should have these columns:\n",
    "  - `user_id`\n",
    "  - `name`\n",
    "  - `funny`\n",
    "- The result rows do NOT need to be ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80f9661399390d017037f14f4a94a307",
     "grade": false,
     "grade_id": "cell-371a339af443edea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Solve the problem by assigning populating the provided variable \n",
    "# with the result of the Spark SQL query\n",
    "\n",
    "def users_kahlil():\n",
    "    return spark.sql(\"\"\"\\\n",
    "        SELECT user_id, name, funny\n",
    "        FROM user\n",
    "        WHERE name = \"Kahlil\"\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3441139d044cfec2158d33419aa5ef3",
     "grade": false,
     "grade_id": "cell-582768a3d45c6227",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+\n",
      "|             user_id|  name|funny|\n",
      "+--------------------+------+-----+\n",
      "|HE5fZW8m7MpdLHa3H...|Kahlil|   32|\n",
      "|BAX7MdujQiv_Camqi...|Kahlil|    0|\n",
      "|fepcVUPERVRA16b4M...|Kahlil|    0|\n",
      "|uvG9MAZF6vIVBoj24...|Kahlil|    4|\n",
      "|sEQtegzBDjARGB_YM...|Kahlil|    0|\n",
      "|JpOCv0TtT2nz0gv0S...|Kahlil|    0|\n",
      "+--------------------+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# It can be helpful to look at the result with .show()\n",
    "\n",
    "results = users_kahlil()\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b59bbf5096c0c4613e71a94cd7eddc1",
     "grade": false,
     "grade_id": "cell-560e6a3ee3481757",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# This notebook provides several asserts for each problem. \n",
    "#\n",
    "# There are also hidden tests that are run by the autograder after submission.\n",
    "\n",
    "assert callable(users_kahlil), \"The answer must be a callable function.\"\n",
    "\n",
    "assert type(users_kahlil()) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The return value should be a Spark DataFrame.\"\n",
    "\n",
    "AutograderHelper.assert_function_calls(users_kahlil, [\"spark.sql\"])\n",
    "\n",
    "users_kahlil_ids = [r[\"user_id\"] for r in users_kahlil().collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4840215fe85ae16d6280cd6937b8ffb5",
     "grade": false,
     "grade_id": "cell-490ace1873a7a27d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(users_kahlil_ids) == 6, \\\n",
    "    \"The result must have 6 rows.\"\n",
    "\n",
    "expected_user_id = \"HE5fZW8m7MpdLHa3HGp1FA\"\n",
    "assert expected_user_id in users_kahlil_ids, f'The user_id column should include \"{expected_user_id}\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cc9f25f3d16a0319f4dde019b12e304",
     "grade": false,
     "grade_id": "cell-0676172ebb6ff73e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## -- USERS WITH 500 FANS --\n",
    "\n",
    "Determine how many users have more than 500 fans.\n",
    "\n",
    "- The result should have 1 column and 1 row\n",
    "- The name of the column does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5088ccde26bc2fe148a019ae565b079a",
     "grade": false,
     "grade_id": "cell-537c97258ccb754f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def count_users_500_fans():\n",
    "    # YOUR CODE HERE\n",
    "    return spark.sql( \"\"\"\n",
    "    Select count(*)\n",
    "    From user\n",
    "    Where fans > 500\n",
    "    \"\"\")\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fae5d266eca8464c6069724e5e652d9f",
     "grade": false,
     "grade_id": "cell-d94241d861c907fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert callable(count_users_500_fans), \"The answer must be a callable function.\"\n",
    "\n",
    "assert type(count_users_500_fans()) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The return value should be a Spark DataFrame.\"\n",
    "\n",
    "AutograderHelper.assert_function_calls(count_users_500_fans, [\"spark.sql\"])\n",
    "\n",
    "count_users_500_fans_submitted = count_users_500_fans().collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad53801803c512af9e8fd879f548485f",
     "grade": false,
     "grade_id": "cell-5fddef372fe914cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert count_users_500_fans_submitted != 8286, \\\n",
    "    \"That is the number of users who have more than 500 funny ratings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7615729333618d8c70c02082d5ef5c2",
     "grade": true,
     "grade_id": "cell-1942c8a3a624ffb1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 2 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bbfd7152afbf1abd8cd32d42c045826",
     "grade": false,
     "grade_id": "cell-fd1250c02e03df22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- BUSINESS REVIEWS --\n",
    "\n",
    "Determine how many businesses have at least 4 stars and at least 100 reviews.\n",
    "\n",
    "- The result should have 1 column and 1 row\n",
    "- The name of the column does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6445fb6ebc9bd4e1b9d88ed933ad89da",
     "grade": false,
     "grade_id": "cell-aa6b3ab08f12e6bc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def business_reviews_count():\n",
    "    return spark.sql( \"\"\"\n",
    "    Select count(*)\n",
    "    From Business\n",
    "    Where stars >= 4 AND review_count >= 100\n",
    "    \"\"\")\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "754e7d1298e8958b30140c4823c3cec4",
     "grade": false,
     "grade_id": "cell-517deb36fd365dbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert callable(business_reviews_count), \"The answer must be a callable function.\"\n",
    "\n",
    "assert type(business_reviews_count()) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The return value should be a Spark DataFrame.\"\n",
    "\n",
    "AutograderHelper.assert_function_calls(business_reviews_count, [\"spark.sql\"])\n",
    "\n",
    "business_reviews_count_submitted = business_reviews_count().collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cae6796829b85cfc2f51efd603c3eb9",
     "grade": false,
     "grade_id": "cell-7717dbfafa0d39a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert business_reviews_count_submitted != 2814, \\\n",
    "    (\n",
    "        \"2814 is the number of businesses with greater than 4 stars (you should include ones with 4 stars) \"\n",
    "        \"and greater than 100 reviews (you should include ones with 100 reviews).\"\n",
    "    )\n",
    "\n",
    "assert business_reviews_count_submitted != 7397, \\\n",
    "    (\n",
    "        \"7397 is the number of businesses with at least 4 stars and greater than 100 reviews (you should \"\n",
    "        \"include ones with 100 reviews).\"\n",
    "    )\n",
    "assert business_reviews_count_submitted != 2842, \\\n",
    "    (\n",
    "        \"2842 is the number of businesses with greater than 4 stars (you should include ones with 4 stars) \"\n",
    "        \"and at least 100 reviews.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1381e2d87a0493f1aa1d5fe9b72c895",
     "grade": true,
     "grade_id": "cell-51af07a99d707639",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 2 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a7ef6f188593d4b5030e7ed6e49f226",
     "grade": false,
     "grade_id": "cell-42472798054d0d9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- LITCHFIELD OHIO --\n",
    "\n",
    "Get a list of businesses from Litchfield, OH. \n",
    "\n",
    "- The result should have these columns:\n",
    "  - `business_id`\n",
    "  - `name`\n",
    "- The result rows do NOT need to be ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b36262572746a2bd83cbc0c878447bdd",
     "grade": false,
     "grade_id": "cell-7363eb8cf90fcf97",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def litchfield_oh_businesses():\n",
    "    # YOUR CODE HERE\n",
    "    return spark.sql( \"\"\"\n",
    "    Select business_id,name\n",
    "    From Business\n",
    "    Where city = 'Litchfield' AND state = 'OH'\n",
    "    \"\"\")\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b149ea8c2fd245162b1cd892cd57d780",
     "grade": false,
     "grade_id": "cell-a51f95eccd981b88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert callable(litchfield_oh_businesses), \"The answer must be a callable function.\"\n",
    "\n",
    "AutograderHelper.assert_function_calls(litchfield_oh_businesses, [\"spark.sql\"])\n",
    "\n",
    "assert type(litchfield_oh_businesses()) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The return value should be a Spark DataFrame.\"\n",
    "\n",
    "litchfield_oh_business_names = [r[\"name\"] for r in litchfield_oh_businesses().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05d283ba5ada33fbdaba6371a2682ee4",
     "grade": false,
     "grade_id": "cell-1338e0791d051601",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"Tonios Pizza\" in litchfield_oh_business_names, \"'Tonios Pizza' should appear in the result.\"\n",
    "assert \"Hayseed\" not in litchfield_oh_business_names, \"'Hayseed' should not appear in the result.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67db5e100119f2a5cde4552acd6b9bc0",
     "grade": true,
     "grade_id": "cell-1a157c9a6f7f7a1f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 2 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e72341fb2311eaf99a9f0532838b7680",
     "grade": false,
     "grade_id": "cell-3f3489b42178d651",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- US STATES --\n",
    "\n",
    "Determine which US states are represented in the data set. (The file `../../assets/data/states.csv` contains a list of US state names and abbreviations.) Part of your task is to import the full names of states and use those values in the result.\n",
    "\n",
    "- The result should have one column:\n",
    "  - `state` (the full name of the state in the dataset)\n",
    "- The result rows do NOT need to be ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = spark.read.option(\"header\", True).csv('../../assets/data/states.csv')\n",
    "states.createOrReplaceTempView(\"states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:=====================================================>(198 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+---------+\n",
      "|    name|total_count|az_count|  percent|\n",
      "+--------+-----------+--------+---------+\n",
      "|    Brad|       1642|    1637|99.695496|\n",
      "|   Karen|       2340|    1559| 66.62393|\n",
      "|Jennifer|       1929|    1250|64.800415|\n",
      "|    Gabi|       1932|    1151| 59.57557|\n",
      "|    Judy|       1193|    1059|88.767815|\n",
      "|Jennifer|       4190|    1059|25.274464|\n",
      "|  Aileen|        934|     908| 97.21627|\n",
      "|    Deni|        855|     850| 99.41521|\n",
      "| Lindsey|       1021|     847|82.957886|\n",
      "|    Juan|       1631|     829|50.827713|\n",
      "+--------+-----------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def percent(a,b):\n",
    "    try:\n",
    "        return ((a/b)*100)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "percent_udf = udf(lambda a,b : percent(a,b), FloatType())\n",
    "spark.udf.register('percent_udf',percent)\n",
    "temp = spark.sql( \"\"\"\n",
    "Select user.name as name,user.review_count as total_count, count(*) as az_count, CAST(percent_udf(count(*),user.review_count) AS FLOAT) as percent\n",
    "From (Select name, user_id, review_count From User) user\n",
    "Inner Join review on\n",
    "user.user_id = review.user_id\n",
    "Inner Join business on\n",
    "review.business_id = business.business_id \n",
    "Where business.state = \"AZ\"\n",
    "Group By user.name,user.user_id, user.review_count\n",
    "Order By az_count DESC, percent DESC\n",
    "Limit 10\n",
    "\"\"\")\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba12ffb90c7bab834fda2bf63d9a04c2",
     "grade": false,
     "grade_id": "cell-f330007b1e3ba3d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def states_names_in_data():\n",
    "    # YOUR CODE HERE\n",
    "    states = spark.read.option(\"header\", True).csv('../../assets/data/states.csv')\n",
    "    states.createOrReplaceTempView(\"states\")\n",
    "    return spark.sql( \"\"\"\n",
    "    Select Distinct states.state\n",
    "    From Business\n",
    "    Inner JOIN states on \n",
    "    states.abbreviation = business.state\n",
    "    \"\"\")\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d11013f48e998f67fc64f77876181abd",
     "grade": false,
     "grade_id": "cell-d5065f190b219da0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert callable(states_names_in_data), \"The answer must be a callable function.\"\n",
    "\n",
    "AutograderHelper.assert_function_calls(states_names_in_data, [\"spark.sql\"])\n",
    "\n",
    "assert type(states_names_in_data()) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The return value should be a Spark DataFrame.\"\n",
    "\n",
    "state_names_list = [r[\"state\"] for r in states_names_in_data().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ea466daea5e068c3b5bd786545b7d98",
     "grade": false,
     "grade_id": "cell-bd73363da3322d4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"North Carolina\" in state_names_list, \"North Carolina should appear in the result.\"\n",
    "assert \"Michigan\" not in state_names_list, \"Michigan should not appear in the result.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9839b561d0c9ba9fad99b30d988c4424",
     "grade": true,
     "grade_id": "cell-3010e95bc0521807",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 3 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d3217f0d9d2d8a6d9a4b2951c3f41f7",
     "grade": false,
     "grade_id": "cell-7753d29b0c281dfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- FUNNIEST REVIEW --\n",
    "\n",
    "Determine the text of the funniest review.\n",
    "\n",
    "- The result should have 1 column and 1 row\n",
    "- The name of the column does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 143:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Flew to Arizona a...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "temp = spark.sql( \"\"\"\n",
    "    Select user.name, count(*) as tip_count\n",
    "    From User\n",
    "    Right Join tip on\n",
    "    user.user_id = tip.user_id\n",
    "    Group By user.name\n",
    "    Order By tip_count DESC, user.name \n",
    "    Limit 100\n",
    "    \"\"\")\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e2f098f481d3ae1835bdd1768826240",
     "grade": false,
     "grade_id": "cell-95b0fdabbf98d3eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def funniest_review():\n",
    "    # YOUR CODE HERE\n",
    "    #Select text \n",
    "    return spark.sql( \"\"\"\n",
    "    Select text\n",
    "    From review\n",
    "    Where funny = (Select MAX(funny) from review)\n",
    "    \"\"\")\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d0e8e668065324f6748b82c1dbca646",
     "grade": false,
     "grade_id": "cell-5083e8c7dede5798",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert callable(funniest_review), \"The answer must be a callable function.\"\n",
    "\n",
    "AutograderHelper.assert_function_calls(funniest_review, [\"spark.sql\"])\n",
    "\n",
    "assert type(funniest_review()) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The return value should be a Spark DataFrame.\"\n",
    "\n",
    "funniest_review_first_row = funniest_review().take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62ac4502ea7300718d8cc474a2d91b31",
     "grade": false,
     "grade_id": "cell-2baca7013c81c4af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "funniest_review_len = len(funniest_review_first_row[0])\n",
    "assert funniest_review_len == 421, \\\n",
    "    f\"Hint: the funniest review has 421 characters (found {funniest_review_len})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ef179dda134deb5e917391f0d93b2a9",
     "grade": true,
     "grade_id": "cell-584ad14e0596f259",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 3 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9796bccc21325e42d51f27d0125c5aa7",
     "grade": false,
     "grade_id": "cell-bd7bf1d844733fc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- MOST TIPS --\n",
    "\n",
    "Determine the names of the top 100 users who provided the most tips.\n",
    "\n",
    "- The result should have these columns:\n",
    "  - `name`\n",
    "  - `tip_count`\n",
    "- The result should be sorted by highest-to-lowest tip_count, in the case of tip_count ties, the results should be sorted by name alphabetically. For example (this is fake data):\n",
    "  ```\n",
    "  +--------+---------+\n",
    "  |    name|tip_count|\n",
    "  +--------+---------+\n",
    "  | Weifong|      167|\n",
    "  |   Alice|       42|\n",
    "  |     Bob|       42|\n",
    "  |   Jamal|        3|\n",
    "  +--------+---------+\n",
    "  ```\n",
    "  \n",
    "Note that not having the secondary sorting can cause subtle bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93ea286599ba9517d563657bdd15b8da",
     "grade": false,
     "grade_id": "cell-2f35829e7a961ef8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def users_top_100_tip_count():\n",
    "    # YOUR CODE HERE\n",
    "    return spark.sql( \"\"\"\n",
    "    Select user.name , count(*) as tip_count\n",
    "    From (Select name, user_id From User) user\n",
    "    Inner Join tip on\n",
    "    user.user_id = tip.user_id\n",
    "    Group By user.user_id, user.name \n",
    "    Order By tip_count DESC, user.name \n",
    "    Limit 100\n",
    "    \"\"\")\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e75f54bdec1863a415f181d04f13ccf",
     "grade": false,
     "grade_id": "cell-6b04bf655b76bca2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert callable(users_top_100_tip_count), \"The answer must be a callable function.\"\n",
    "\n",
    "AutograderHelper.assert_function_calls(users_top_100_tip_count, [\"spark.sql\"])\n",
    "\n",
    "assert type(users_top_100_tip_count()) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The return value should be a Spark DataFrame.\"\n",
    "\n",
    "users_top_100_tip_count_first_row = users_top_100_tip_count().take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da59d9355490fc1b90bad1dc3655d5c5",
     "grade": false,
     "grade_id": "cell-36b874e02c6055dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert users_top_100_tip_count_first_row[\"name\"] == \"Momo\", \"The first name should be Momo\"\n",
    "assert users_top_100_tip_count_first_row[\"tip_count\"] == 2439, \"The first tip_count should be 2439\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "270d5b6b85a29050758d488dd0c65700",
     "grade": true,
     "grade_id": "cell-346b2d93ee722e0e",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 4 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "538d1ad4e894c2b74907dc4211242fe6",
     "grade": false,
     "grade_id": "cell-3ea13d4f07b462c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- ARIZONA SUMMARY -- \n",
    "\n",
    "List the names, number of reviews of businesses in Arizona ('AZ') and total number of reviews of the top 10 users (as determined by who has created the most number of reviews of businesses in Arizona). Include a column that shows the percentage of reviews that are of businesses from Arizona. \n",
    "\n",
    "- The result should have these columns:\n",
    "  - `name`\n",
    "  - `az_count`\n",
    "  - `total_count` (Use the \"user\" table's \"review_count\" column for this value)\n",
    "  - `percent` (this will only be checked to within 0.01)\n",
    "- The result should be sorted by highest-to-lowest `az_count`, in the case of `az_count ties`, the results should be sorted by highest-to-lowest `percent`\n",
    "\n",
    "\n",
    "\n",
    "The first row of the results should be:\n",
    "```\n",
    "+--------+--------+-----------+---------+\n",
    "|    name|az_count|total_count|  percent|\n",
    "+--------+--------+-----------+---------+\n",
    "|    Brad|    1637|       1642|99.695496|\n",
    "+--------+--------+-----------+---------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85877f47ca43829a5c491ca9ed0f6e75",
     "grade": false,
     "grade_id": "cell-58c41d2bcaae305b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def percent(a,b):\n",
    "    try:\n",
    "        return ((a/b)*100)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "def arizona_summary():\n",
    "    from pyspark.sql.types import FloatType\n",
    "    from pyspark.sql.functions import udf\n",
    "    percent_udf = udf(lambda a,b : percent(a,b), FloatType())\n",
    "    spark.udf.register('percent_udf',percent)\n",
    "    return spark.sql( \"\"\"\n",
    "    Select user.name as name,user.review_count as total_count, count(*) as az_count, CAST(percent_udf(count(*),user.review_count) AS FLOAT) as percent\n",
    "    From (Select name, user_id, review_count From User) user\n",
    "    Inner Join review on\n",
    "    user.user_id = review.user_id\n",
    "    Inner Join business on\n",
    "    review.business_id = business.business_id \n",
    "    Where business.state = \"AZ\"\n",
    "    Group By user.user_id, user.name, user.review_count\n",
    "    Order By az_count DESC, percent DESC\n",
    "    Limit 10\n",
    "    \"\"\")\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "840eda4fcd771ad00d3c48675d27ceb5",
     "grade": false,
     "grade_id": "cell-9c8b7064d916064b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert callable(arizona_summary), \"The answer must be a callable function.\"\n",
    "\n",
    "AutograderHelper.assert_function_calls(arizona_summary, [\"spark.sql\"])\n",
    "\n",
    "assert type(arizona_summary()) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The return value should be a Spark DataFrame.\"\n",
    "\n",
    "arizona_summary_first_row = arizona_summary().take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fedeecbede385e1397cf962a758affb4",
     "grade": false,
     "grade_id": "cell-8a0509444e910378",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert arizona_summary_first_row[\"name\"] == \"Brad\", \"The first name should be Brad\"\n",
    "assert arizona_summary_first_row[\"az_count\"] == 1637, \"The first az_count should be 1637\"\n",
    "assert arizona_summary_first_row[\"total_count\"] == 1642, \"The first total_count should be 1642\"\n",
    "\n",
    "assert round(arizona_summary_first_row[\"percent\"], 2) == 99.70, \\\n",
    "    (\n",
    "        f\"The first percent should be about 99.70 (checking to \"\n",
    "        f\"nearest 0.01, found {arizona_summary_first_row['percent']})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac61214feea77310de7083b9b35c64e5",
     "grade": true,
     "grade_id": "cell-a5e177b11e33c438",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 4 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_big_data_scalable_data_processing_v3_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
